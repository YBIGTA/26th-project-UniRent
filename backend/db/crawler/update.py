from crawler.crawler import ThreeThreeCrawler, HowBoutHereCrawler
from database.mongodb_connection import MongoDB
from app.dependencies import get_mongodb
from time import sleep

def update_func(db: MongoDB, output_dir: str = "./output", place: str = "ì„œëŒ€ë¬¸êµ¬"):
    """
    ê° ì‚¬ì´íŠ¸ë³„(ë‹¨ê¸°ì„ëŒ€, ëª¨í…”) í¬ë¡¤ë§ í›„ DB ì—…ë°ì´íŠ¸:
      - ê¸°ì¡´ DBì˜ ì œëª© ëª©ë¡(prev_titles)ì„ ê°€ì ¸ì™€ì„œ,
      - ìƒˆë¡œ í¬ë¡¤ë§í•œ ë°ì´í„° ì¤‘ ì‹ ê·œ í•­ëª©(new_data)ì„ DBì— ì¶”ê°€í•˜ê³ ,
      - ê¸°ì¡´ DBì— ìˆì—ˆìœ¼ë‚˜ í¬ë¡¤ë§ ê²°ê³¼ì— ì—†ëŠ” í•­ëª©ì€ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    # ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬ì™€ property type ë§¤í•‘
    crawler_mapping = {
        "threethree": (ThreeThreeCrawler, "ë‹¨ê¸°ì„ëŒ€"),
        "howbouthere": (HowBoutHereCrawler, "ëª¨í…”")
    }

    for key, (crawler_cls, prop_type) in crawler_mapping.items():
        # DBì—ì„œ í•´ë‹¹ íƒ€ì…ì˜ ê¸°ì¡´ ì œëª© ëª©ë¡ ì¡°íšŒ
        prev_titles = db.get_titles_by_type(prop_type)
        
        # í•´ë‹¹ í¬ë¡¤ëŸ¬ ì‹¤í–‰ (ì œëª©ë§Œ ê°€ì ¸ì˜´)
        crawler = crawler_cls(output_dir, place)
        crawler.search_titles()
        
        # ì‹ ê·œ ë°ì´í„° (DBì— ì—†ëŠ” ì œëª©) ì„ ë³„
        new_titles = [room["title"] for room in crawler.data if room.get("title")]
        new_data = [title for title in new_titles if title not in prev_titles]

        # ğŸ”¹ ì‹ ê·œ í•­ëª©ì— ëŒ€í•´ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        detailed_data = []
        for title in new_data:
            room_details = crawler.scrape_review_by_title(title)  # ğŸ”¥ ì¶”ê°€ëœ í•¨ìˆ˜
            if room_details:
                detailed_data.append(room_details)

        # ğŸ”¹ ì‹ ê·œ í•­ëª©ì„ DBì— ì¶”ê°€
        if detailed_data:
            db.add_properties(detailed_data, prop_type)

        # ğŸ”¹ ê¸°ì¡´ DBì— ìˆì—ˆìœ¼ë‚˜ í¬ë¡¤ë§ ê²°ê³¼ì— ì—†ëŠ” í•­ëª© ì‚­ì œ
        to_delete = list(set(prev_titles) - set(new_titles))
        if to_delete:
            db.delete_properties_by_titles(to_delete)
    
    db.close()
